{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tracking Experiments with AIM\n",
        "\n",
        "In this guide, we'll talk about how you can use the open source tracker [AIM](https://github.com/aimhubio/aim) to keep track of your ML experiments."
      ],
      "metadata": {
        "id": "MV7w4XmvK5bZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TE2J70dCISCW"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install aim transformers datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Usage\n",
        "\n",
        "AIM, like other loggers you may have used in the past, has a fairly simple user-facing API for creating and logging experiments.\n",
        "\n",
        "  - âœ… First, you initialize a \"Run\". A run represents a single training experiment.\n",
        "  - ðŸ“ From there, you can add some metadata to the run object, treating it sort of like a dictionary. Below, we log some fake hyperparameters for the run. \n",
        "  - ðŸ“ˆ To log metrics in your run, you call the `run.track` function, supplying the metric you want to track, a name for it, and the timestep associated with it.\n",
        "    - Additionally, you can supply \"context\" which will let you filter/sort/group this metric with other related metrics. Below we specify \"train\" as a subset, but you could also do \"eval\" and \"test\" subsets (or whatever you want, really)"
      ],
      "metadata": {
        "id": "6ABNX3hvLNBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from aim import Run\n",
        "\n",
        "# Initialize a new run\n",
        "run = Run()\n",
        "\n",
        "# Log run parameters\n",
        "run[\"hparams\"] = {\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"batch_size\": 32,\n",
        "}\n",
        "\n",
        "# Log metrics\n",
        "for i in range(10):\n",
        "    run.track(i, name='loss', step=i, context={\"subset\": \"train\"})\n",
        "    run.track(i, name='acc', step=i, context={\"subset\": \"train\"})"
      ],
      "metadata": {
        "id": "8R4rFV_0y8Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll view these logs in the browser in a minute! First, let's see a slightly more realistic example of tracking with AIM..."
      ],
      "metadata": {
        "id": "OkqWaoK69yms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Usage with Hugging Face `transformers`\n",
        "\n",
        "As a more involved example, let's take a look at how you can use AIM to track experiments using the Hugging Face [`transformers`](https://github.com/huggingface/transformers) library.\n",
        "\n",
        "First, let's write a quick example to train a text classification model. Specifically, we'll be fine-tuning bert-base-cased on the [IMDB reviews](https://huggingface.co/datasets/imdb) dataset."
      ],
      "metadata": {
        "id": "5CinIKDILUUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, default_data_collator\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset + take a small sample of it\n",
        "ds = load_dataset(\"imdb\")\n",
        "del ds['unsupervised']  # discarding this split as we won't need it\n",
        "ds['train'] = ds['train'].shuffle(seed=42).select(range(5000))\n",
        "ds['test'] = ds['test'].shuffle(seed=42).select(range(5000))\n",
        "\n",
        "# Rename label -> labels so inputs can be **unpacked into model call fn in Trainer\n",
        "ds = ds.rename_column(\"label\", \"labels\")\n",
        "\n",
        "# Get the labels from the dataset + sort them so we can add this info to model config\n",
        "labels = ds[\"train\"].unique(\"labels\")\n",
        "labels.sort()\n",
        "\n",
        "# Initialize the model, supplying num_labels/label mappings to reinit classification head\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-cased\",\n",
        "    num_labels=len(labels),\n",
        "    return_dict=True,\n",
        "    label2id={x: i for i, x in enumerate(labels)},\n",
        "    id2label=dict(enumerate(labels)),\n",
        ")\n",
        "\n",
        "# Initialize tokenizer and define processing fn to apply to dataset\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# Apply the processing fn, removing unnecessary text column\n",
        "ds = ds.map(tokenize_function, batched=True, remove_columns=['text'])\n",
        "\n",
        "# Define a fn to compute evaluation accuracy\n",
        "def compute_metrics(pred):\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    acc = np.sum(preds == pred.label_ids) / preds.shape[0]\n",
        "    return {'acc': acc}"
      ],
      "metadata": {
        "id": "BQ76DIWazsmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we set up the `AimCallback`, which is a handy [`transformers.TrainingCallback`](https://huggingface.co/docs/transformers/v4.24.0/en/main_classes/callback#transformers.TrainerCallback) that comes with `aim`. Then, we define the training configuration and the trainer, making sure to disable other loggers and provide our callback instance.\n",
        "\n",
        "Then, we train! ðŸš€"
      ],
      "metadata": {
        "id": "e9kwgxr8-twb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from aim.hugging_face import AimCallback\n",
        "\n",
        "# Set up AIM logger\n",
        "aim_callback = AimCallback(experiment='huggingface_experiment')\n",
        "\n",
        "# Define training configuration, setting report_to='none' because we will use aim instead\n",
        "training_args = TrainingArguments(\n",
        "    'bert-base-cased-imdb-sample',\n",
        "    evaluation_strategy='epoch',\n",
        "    num_train_epochs=4,\n",
        "    report_to=\"none\",\n",
        "    logging_steps=10,\n",
        "    per_device_train_batch_size=8,\n",
        ")\n",
        "\n",
        "# Initialize trainer, supplying the aim callback\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    data_collator=default_data_collator,\n",
        "    callbacks=[aim_callback],\n",
        "    train_dataset=ds['train'],\n",
        "    eval_dataset=ds['test'],\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train!\n",
        "train_result = trainer.train()"
      ],
      "metadata": {
        "id": "lBhmhOqJz_2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View the Runs\n",
        "\n",
        "Finally, we can view both our dummy run and our `transformers` run. ðŸ‘€\n",
        "\n",
        "Note - If you aren't running this in a notebook, you can simply run `aim up` in your terminal to launch the viewer locally."
      ],
      "metadata": {
        "id": "ggw0gs0kMCYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext aim"
      ],
      "metadata": {
        "id": "0gnXxFB6MDxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aim up"
      ],
      "metadata": {
        "id": "xQ4CSXPTMEpc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}